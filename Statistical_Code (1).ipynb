{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C24CdWcf5RLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c04c30-11bb-493e-d055-274859e32eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List your excel file names\n",
        "files = [\n",
        "    \"/content/drive/MyDrive/radiomics_results/3DAttention_Train_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_072032 (1).xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Medsam_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-10-2025_190548.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Original_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-09-2025_153824.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Reconnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_115208.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/ResUnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_120730.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Vnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_225322.xlsx\"\n",
        "]\n",
        "\n",
        "# Read all files\n",
        "dfs = [pd.read_excel(f) for f in files]\n",
        "\n",
        "# Step 1: Get the intersection of PatientIDs across all files\n",
        "common_ids = set(dfs[0].iloc[:, 0])  # first column assumed to be PatientID\n",
        "for df in dfs[1:]:\n",
        "    common_ids &= set(df.iloc[:, 0])\n",
        "\n",
        "print(f\"Number of common PatientIDs across all files: {len(common_ids)}\")\n",
        "\n",
        "# Step 2: Filter each DataFrame to keep only common PatientIDs\n",
        "filtered_dfs = [df[df.iloc[:, 0].isin(common_ids)] for df in dfs]\n",
        "\n",
        "# Step 3: Save the filtered DataFrames back\n",
        "for f, df in zip(files, filtered_dfs):\n",
        "    out_name = f\"{f}\"\n",
        "    df.to_excel(out_name, index=False)\n",
        "    print(f\"Saved: {out_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzrZReNQYOfy",
        "outputId": "5a77f933-55f6-4d6b-e557-812d12ebe79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of common PatientIDs across all files: 736\n",
            "Saved: /content/drive/MyDrive/radiomics_results/3DAttention_Train_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_072032 (1).xlsx\n",
            "Saved: /content/drive/MyDrive/radiomics_results/Medsam_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-10-2025_190548.xlsx\n",
            "Saved: /content/drive/MyDrive/radiomics_results/Original_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-09-2025_153824.xlsx\n",
            "Saved: /content/drive/MyDrive/radiomics_results/Reconnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_115208.xlsx\n",
            "Saved: /content/drive/MyDrive/radiomics_results/ResUnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_120730.xlsx\n",
            "Saved: /content/drive/MyDrive/radiomics_results/Vnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_225322.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "def shapiro_wilk_test(train_df, test_df, id_col=\"patient_id\", alpha=0.05, sample_size=5000):\n",
        "    \"\"\"\n",
        "    Apply Shapiro-Wilk test for normality on all columns (except patient_id)\n",
        "    for both train and test datasets.\n",
        "\n",
        "    Parameters:\n",
        "        train_df (pd.DataFrame): Training dataset with features + patient_id\n",
        "        test_df (pd.DataFrame): Test dataset with features + patient_id\n",
        "        id_col (str): Column name for patient ID\n",
        "        alpha (float): Significance level for hypothesis testing\n",
        "        sample_size (int): Maximum sample size for Shapiro-Wilk test (scipy limitation)\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Summary results for each feature and dataset\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for dataset_name, df in [(\"train\", train_df), (\"test\", test_df)]:\n",
        "        for col in df.columns:\n",
        "            if col == id_col:\n",
        "                continue  # skip patient ID column\n",
        "\n",
        "            data = df[col].dropna().values\n",
        "\n",
        "            # Shapiro test does not work with huge samples; limit size if needed\n",
        "            if len(data) > sample_size:\n",
        "                data = data[:sample_size]\n",
        "\n",
        "            stat, p_value = shapiro(data)\n",
        "\n",
        "            normality = \"Normal\" if p_value > alpha else \"Not Normal\"\n",
        "            results.append({\n",
        "                \"Dataset\": dataset_name,\n",
        "                \"Feature\": col,\n",
        "                \"Statistic\": stat,\n",
        "                \"p-value\": p_value,\n",
        "                \"Normality\": normality\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "train_df = pd.read_excel(\"/content/drive/MyDrive/radiomics_results/ResUnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_120730.xlsx\")\n",
        "test_df = pd.read_excel(\"/content/drive/MyDrive/radiomics_results/ResUnet_Test_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_031827.xlsx\")\n",
        "train_df = train_df.iloc[:, 1:-1]   # removes column at index 0 (first) and last column\n",
        "test_df  = test_df.iloc[:, 1:-1]\n",
        "results = shapiro_wilk_test(train_df, test_df, id_col=\"patient_id\")\n",
        "results.to_excel(\"/content/drive/MyDrive/radiomics_results/shapiro_results/ResUnet.xlsx\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F8p6SZIaFfx",
        "outputId": "12767399-2400-4ed1-f7d3-cf8f3f6f0822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/stats/_axis_nan_policy.py:579: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n",
            "/tmp/ipython-input-1349000784.py:32: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
            "  stat, p_value = shapiro(data)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pingouin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVWsyt-WK9Hu",
        "outputId": "cce02baa-d8b0-44a7-f34c-452f0f9dfc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pingouin\n",
            "  Downloading pingouin-0.5.5-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pingouin) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pingouin) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.12/dist-packages (from pingouin) (2.2.2)\n",
            "Collecting pandas-flavor (from pingouin)\n",
            "  Downloading pandas_flavor-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from pingouin) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pingouin) (1.16.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.13.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.14.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from pingouin) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->pingouin) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->pingouin) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5->pingouin) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->pingouin) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->pingouin) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pingouin) (3.2.4)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (from pandas-flavor->pingouin) (2025.9.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->pingouin) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5->pingouin) (1.17.0)\n",
            "Downloading pingouin-0.5.5-py3-none-any.whl (204 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.4/204.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas_flavor-0.7.0-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: pandas-flavor, pingouin\n",
            "Successfully installed pandas-flavor-0.7.0 pingouin-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "import pingouin as pg\n",
        "\n",
        "# ---- CONFIG ----\n",
        "# ground truth train/test\n",
        "ground_truth_train = \"/content/drive/MyDrive/radiomics_results/Original_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-09-2025_153824.xlsx\"\n",
        "ground_truth_test  = \"/content/drive/MyDrive/radiomics_results/Original_Test_data_All_extracted_features_OPTIMIZED_sequential_CT_08-29-2025_180537.xlsx\"\n",
        "\n",
        "# generated train/test (parallel files to compare with GT)\n",
        "generated_train_files = [\n",
        "    \"/content/drive/MyDrive/radiomics_results/3DAttention_Train_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_072032 (1).xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Medsam_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-10-2025_190548.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/ResUnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_120730.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Reconnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_115208.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Vnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_225322.xlsx\"\n",
        "]\n",
        "\n",
        "generated_test_files = [\n",
        "    \"/content/drive/MyDrive/radiomics_results/3DAttention_Test_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_072032 (1).xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Medsam_Test_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-10-2025_085007.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/ResUnet_Test_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_031827.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Reconnet_Test_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_032250.xlsx\",\n",
        "    \"/content/drive/MyDrive/radiomics_results/Vnet_Test_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_031026 (1).xlsx\"\n",
        "]\n",
        "\n",
        "# ---- Helper: compute reproducibility ----\n",
        "def compute_reproducibility(gt_file, gen_file):\n",
        "    gt_df = pd.read_excel(gt_file).dropna()\n",
        "    gen_df = pd.read_excel(gen_file).dropna()\n",
        "\n",
        "    patient_col = gt_df.columns[0]\n",
        "    features = gt_df.columns[1:]\n",
        "\n",
        "    # Align by PatientID\n",
        "    merged = pd.merge(gt_df, gen_df, on=patient_col, suffixes=(\"_GT\", \"_GEN\"))\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for feat in features:\n",
        "        gt_vals = merged[f\"{feat}_GT\"].values\n",
        "        gen_vals = merged[f\"{feat}_GEN\"].values\n",
        "\n",
        "        # Spearman\n",
        "        rho, pval = spearmanr(gt_vals, gen_vals)\n",
        "        # ICC(2,1)\n",
        "        df_icc = pd.DataFrame({\n",
        "            \"Subject\": np.tile(np.arange(len(gt_vals)), 2),   # repeat subjects twice\n",
        "            \"Rater\": np.repeat([1, 2], len(gt_vals)),         # 1 = GT, 2 = Generated\n",
        "            \"Score\": np.concatenate([gt_vals, gen_vals])      # stack values\n",
        "        })\n",
        "\n",
        "\n",
        "        try:\n",
        "            icc_table = pg.intraclass_corr(data=df_icc,\n",
        "                                           targets=\"Subject\",\n",
        "                                           raters=\"Rater\",\n",
        "                                           ratings=\"Score\").round(3)\n",
        "            icc_score = icc_table.loc[icc_table[\"Type\"] == \"ICC2\", \"ICC\"].values[0]\n",
        "        except Exception as e:\n",
        "            icc_score = np.nan\n",
        "\n",
        "        results.append([feat, icc_score, rho, pval])\n",
        "\n",
        "    df_res = pd.DataFrame(results, columns=[\"Feature\", \"ICC(2,1)\", \"Spearman_rho\", \"Spearman_pval\"])\n",
        "\n",
        "    # Add aggregates\n",
        "    agg_row = pd.DataFrame([[\n",
        "        \"AVERAGE\",\n",
        "        df_res[\"ICC(2,1)\"].mean(),\n",
        "        df_res[\"Spearman_rho\"].mean(),\n",
        "        df_res[\"Spearman_pval\"].mean()\n",
        "    ]], columns=df_res.columns)\n",
        "\n",
        "    df_res = pd.concat([df_res, agg_row], ignore_index=True)\n",
        "    return df_res\n",
        "\n",
        "\n",
        "# ---- Run for all datasets ----\n",
        "results = {}\n",
        "\n",
        "# Train\n",
        "for gen_file in generated_train_files:\n",
        "    name = gen_file.split(\"/\")[-1].replace(\".xlsx\", \"\")\n",
        "    results[name] = compute_reproducibility(ground_truth_train, gen_file)\n",
        "\n",
        "# Test\n",
        "for gen_file in generated_test_files:\n",
        "    name = gen_file.split(\"/\")[-1].replace(\".xlsx\", \"\")\n",
        "    results[name] = compute_reproducibility(ground_truth_test, gen_file)\n",
        "\n",
        "# ---- Save Excel ----\n",
        "with pd.ExcelWriter(\"/content/drive/MyDrive/radiomics_results/reproducibility_results.xlsx\") as writer:\n",
        "    for name, df in results.items():\n",
        "        df.to_excel(writer, sheet_name=name[:30], index=False)\n",
        "\n",
        "print(\"✅ Reproducibility results (ICC + Spearman) saved in 'reproducibility_results.xlsx'\")\n"
      ],
      "metadata": {
        "id": "Gd040zWiKHBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_rel, wilcoxon\n",
        "from statsmodels.multivariate.manova import MANOVA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ------------------\n",
        "# Replace with your actual file paths\n",
        "# ------------------\n",
        "ground_train_path = \"/content/drive/MyDrive/radiomics_results/Original_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-09-2025_153824.xlsx\"\n",
        "ground_test_path = \"/content/drive/MyDrive/radiomics_results/Original_Test_data_All_extracted_features_OPTIMIZED_sequential_CT_08-29-2025_180537.xlsx\"\n",
        "generated_paths = { \"3DAttention\": (\"/content/drive/MyDrive/radiomics_results/3DAttention_Train_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_072032 (1).xlsx\", \"/content/drive/MyDrive/radiomics_results/3DAttention_Test_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_072032 (1).xlsx\"), \"MedSam\": (\"/content/drive/MyDrive/radiomics_results/Medsam_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-10-2025_190548.xlsx\", \"/content/drive/MyDrive/radiomics_results/Medsam_Test_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-10-2025_085007.xlsx\"), \"ResUNet\": (\"/content/drive/MyDrive/radiomics_results/ResUnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_120730.xlsx\", \"/content/drive/MyDrive/radiomics_results/ResUnet_Test_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_031827.xlsx\"), \"ReconNet\": (\"/content/drive/MyDrive/radiomics_results/Reconnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_115208.xlsx\", \"/content/drive/MyDrive/radiomics_results/Reconnet_Test_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_032250.xlsx\"), \"VNet\": (\"/content/drive/MyDrive/radiomics_results/Vnet_Train_Data_All_extracted_features_OPTIMIZED_sequential_CT_09-04-2025_225322.xlsx\", \"/content/drive/MyDrive/radiomics_results/Vnet_Test_Data_All_extracted_features_OPTIMIZED_preprocessed_sequential_CT_08-25-2025_031026 (1).xlsx\"), }\n",
        "# Load ground truth\n",
        "ground_train = pd.read_excel(ground_train_path)\n",
        "ground_test  = pd.read_excel(ground_test_path)\n",
        "\n",
        "# ------------------\n",
        "# Function to align datasets by PatientID\n",
        "# ------------------\n",
        "def align_datasets(df_gt, df_gen):\n",
        "    merged = pd.merge(df_gt, df_gen, on=df_gt.columns[0], suffixes=(\"_gt\", \"_gen\"))\n",
        "    return merged\n",
        "\n",
        "# ------------------\n",
        "# Function to run stats on one dataset (train/test)\n",
        "# ------------------\n",
        "def run_stats(merged, set_name):\n",
        "    feature_cols_gt  = [c for c in merged.columns if c.endswith(\"_gt\")]\n",
        "    feature_cols_gen = [c for c in merged.columns if c.endswith(\"_gen\")]\n",
        "\n",
        "    # ---- 1. Paired t-test ----\n",
        "    ttest_rows = []\n",
        "    for f_gt, f_gen in zip(feature_cols_gt, feature_cols_gen):\n",
        "        x, y = merged[f_gt], merged[f_gen]\n",
        "        try:\n",
        "            t_stat, t_pval = ttest_rel(x, y, nan_policy=\"omit\")\n",
        "        except Exception:\n",
        "            t_stat, t_pval = np.nan, np.nan\n",
        "        ttest_rows.append([f_gt.replace(\"_gt\", \"\"), t_stat, t_pval])\n",
        "    df_ttest = pd.DataFrame(ttest_rows, columns=[\"Feature\", \"T_statistic\", \"P_value\"])\n",
        "\n",
        "    # ---- 2. Wilcoxon ----\n",
        "    wilcoxon_rows = []\n",
        "    for f_gt, f_gen in zip(feature_cols_gt, feature_cols_gen):\n",
        "        x, y = merged[f_gt], merged[f_gen]\n",
        "        try:\n",
        "            w_stat, w_pval = wilcoxon(x, y)\n",
        "        except Exception:\n",
        "            w_stat, w_pval = np.nan, np.nan\n",
        "        wilcoxon_rows.append([f_gt.replace(\"_gt\", \"\"), w_stat, w_pval])\n",
        "    df_wilcoxon = pd.DataFrame(wilcoxon_rows, columns=[\"Feature\", \"W_statistic\", \"P_value\"])\n",
        "\n",
        "    # ---- 3. MANOVA with PCA ----\n",
        "    try:\n",
        "        records = []\n",
        "        for f_gt, f_gen in zip(feature_cols_gt, feature_cols_gen):\n",
        "            feature_name = f_gt.replace(\"_gt\",\"\")\n",
        "            for pid, gt_val, gen_val in zip(merged.iloc[:,0], merged[f_gt], merged[f_gen]):\n",
        "                records.append({\"PatientID\": pid, \"Group\": \"GT\", feature_name: gt_val})\n",
        "                records.append({\"PatientID\": pid, \"Group\": \"GEN\", feature_name: gen_val})\n",
        "        manova_df = pd.DataFrame(records)\n",
        "\n",
        "        manova_df = manova_df.pivot_table(index=[\"PatientID\",\"Group\"],\n",
        "                                          values=[c for c in manova_df.columns if c not in [\"PatientID\",\"Group\"]],\n",
        "                                          aggfunc=\"first\").reset_index()\n",
        "\n",
        "        feature_cols = [c for c in manova_df.columns if c not in [\"PatientID\",\"Group\"]]\n",
        "        X = manova_df[feature_cols].fillna(0).values\n",
        "\n",
        "        n_components = min(20, X.shape[1])\n",
        "        pca = PCA(n_components=n_components)\n",
        "        X_pca = pca.fit_transform(X)\n",
        "\n",
        "        pca_cols = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
        "        X_df = pd.DataFrame(X_pca, columns=pca_cols)\n",
        "        X_df[\"Group\"] = manova_df[\"Group\"].values\n",
        "\n",
        "        formula = f\"{' + '.join(pca_cols)} ~ Group\"\n",
        "        maov = MANOVA.from_formula(formula, data=X_df)\n",
        "        manova_summary = maov.mv_test()\n",
        "\n",
        "        stat_table = manova_summary.results[\"Group\"][\"stat\"].copy()\n",
        "        stat_table.index.name = \"Test\"\n",
        "        df_manova = stat_table.reset_index()\n",
        "\n",
        "        pvals = df_manova[\"Pr > F\"].astype(float)\n",
        "        decision = \"Reject H0 (Significant difference)\" if (pvals < 0.05).any() else \"Fail to reject H0 (No significant difference)\"\n",
        "        summary_row = pd.DataFrame([[\"Overall Decision\", \"-\", \"-\", \"-\", \"-\", decision]],\n",
        "                                   columns=df_manova.columns)\n",
        "        df_manova = pd.concat([df_manova, summary_row], ignore_index=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        df_manova = pd.DataFrame({\"Error\": [str(e)]})\n",
        "\n",
        "    return {f\"Paired_ttest_{set_name}\": df_ttest,\n",
        "            f\"Wilcoxon_{set_name}\": df_wilcoxon,\n",
        "            f\"MANOVA_{set_name}\": df_manova}\n",
        "\n",
        "\n",
        "# ------------------\n",
        "# Run for each generator (train & test separately)\n",
        "# ------------------\n",
        "for gen_name, (gen_train_path, gen_test_path) in generated_paths.items():\n",
        "    gen_train = pd.read_excel(gen_train_path)\n",
        "    gen_test  = pd.read_excel(gen_test_path)\n",
        "\n",
        "    merged_train = align_datasets(ground_train, gen_train)\n",
        "    merged_test  = align_datasets(ground_test, gen_test)\n",
        "\n",
        "    stats_train = run_stats(merged_train, \"Train\")\n",
        "    stats_test  = run_stats(merged_test, \"Test\")\n",
        "\n",
        "    out_path = f\"/content/drive/MyDrive/radiomics_results/reproducibility_stats_{gen_name}.xlsx\"\n",
        "    with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
        "        for sheet_name, df in {**stats_train, **stats_test}.items():\n",
        "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "    print(f\"✅ Saved results for {gen_name} -> {out_path}\")\n"
      ],
      "metadata": {
        "id": "npNTdxW9uTJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# ================= Configurable Parameters =================\n",
        "folder_path = \"/content/drive/MyDrive/radiomics_results/eval_stat\"\n",
        "colors = {\"whole\": \"#1D0FDB\", \"crop\": \"#DB0F38\"}\n",
        "figsize = (16, 8)\n",
        "ymin, ymax, ystep = 0.0, 45, 4\n",
        "line_thickness = 1.5\n",
        "line_style = \"--\"\n",
        "line_color = \"#383535\"\n",
        "# ===========================================================\n",
        "\n",
        "# Load and merge all Excel files\n",
        "all_dfs = []\n",
        "for file in glob.glob(os.path.join(folder_path, \"*.xlsx\")):\n",
        "    model_name = os.path.splitext(os.path.basename(file))[0]\n",
        "    if any(m in model_name for m in [\"3DAttention\",\"MedSam\",\"ResUNet\",\"ReconNet\",\"VNet\"]):\n",
        "        df = pd.read_excel(file)\n",
        "        if \"whole\" in model_name.lower():\n",
        "            category = \"whole\"\n",
        "        elif \"crop\" in model_name.lower():\n",
        "            category = \"crop\"\n",
        "        else:\n",
        "            raise ValueError(f\"Category not found in {file}\")\n",
        "\n",
        "        df[\"Model\"] = next(m for m in [\"3DAttention\",\"MedSam\",\"ResUNet\",\"ReconNet\",\"VNet\"] if m in model_name)\n",
        "        df[\"Category\"] = category\n",
        "        all_dfs.append(df)\n",
        "\n",
        "data = pd.concat(all_dfs, ignore_index=True)\n",
        "data.rename(columns=lambda x: x.strip(), inplace=True)  # strip spaces\n",
        "# ================= Plotting =================\n",
        "sns.set(style=\"whitegrid\", font_scale=1)\n",
        "plt.figure(figsize=figsize)\n",
        "ax = plt.gca()\n",
        "\n",
        "# --- Boxplots ---\n",
        "sns.boxplot(\n",
        "    data=data,\n",
        "    x=\"Model\",\n",
        "    y=\"Hausdorff Distance\",\n",
        "    hue=\"Category\",\n",
        "    palette=colors,\n",
        "    width=0.4,\n",
        "    dodge=True,\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# --- Scatter points ---\n",
        "sns.stripplot(\n",
        "    data=data,\n",
        "    x=\"Model\",\n",
        "    y=\"Hausdorff Distance\",\n",
        "    hue=\"Category\",\n",
        "    dodge=True,\n",
        "    palette=colors,\n",
        "    alpha=0.7,\n",
        "    linewidth=0.5,\n",
        "    edgecolor=\"black\",\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Remove duplicate legends (since both box & strip added)\n",
        "# handles, labels = ax.get_legend_handles_labels()\n",
        "# ax.legend(handles[:2], labels[:2], title=\"Category\")\n",
        "\n",
        "# --- Extract median line positions ---\n",
        "median_positions = {}\n",
        "for line in ax.lines:\n",
        "    if line.get_linestyle() == '-' and np.isclose(line.get_ydata()[0], line.get_ydata()[1]):\n",
        "        # This is a median line\n",
        "        x_coords = line.get_xdata()\n",
        "        y_coords = line.get_ydata()\n",
        "        median_x = np.mean(x_coords)\n",
        "        median_y = y_coords[0]\n",
        "\n",
        "        # Find nearest tick (model index)\n",
        "        model_idx = int(round(median_x))\n",
        "        if 0 <= model_idx < len(ax.get_xticks()):\n",
        "            model_name = ax.get_xticklabels()[model_idx].get_text()\n",
        "\n",
        "            # Decide which category: left (whole) or right (crop)\n",
        "            if median_x < model_idx:\n",
        "                cat = \"whole\"\n",
        "            else:\n",
        "                cat = \"crop\"\n",
        "\n",
        "            median_positions.setdefault(model_name, {})[cat] = (median_x, median_y)\n",
        "\n",
        "# --- Draw connecting lines ---\n",
        "for model, coords in median_positions.items():\n",
        "    if \"whole\" in coords and \"crop\" in coords:\n",
        "        x_vals = [coords[\"whole\"][0], coords[\"crop\"][0]]\n",
        "        y_vals = [coords[\"whole\"][1], coords[\"crop\"][1]]\n",
        "        ax.plot(\n",
        "            x_vals, y_vals,\n",
        "            linestyle=line_style,\n",
        "            linewidth=line_thickness,\n",
        "            color=line_color\n",
        "        )\n",
        "\n",
        "# --- Customization ---\n",
        "ax.set_ylim(ymin, ymax)\n",
        "ax.set_yticks(np.arange(ymin, ymax + ystep, ystep))\n",
        "ax.legend_.remove()\n",
        "for spine in ax.spines.values():\n",
        "    spine.set_visible(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"/content/drive/MyDrive/val_Hausdorff.png\", dpi=400, bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N9SqYcwUdVoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# ================= Configurable Parameters =================\n",
        "folder_path = \"/content/drive/MyDrive/radiomics_results/eval_stat\"\n",
        "colors = {\"whole\": \"#1D0FDB\", \"crop\": \"#DB0F38\"}\n",
        "figsize = (16, 8)\n",
        "ymin, ymax, ystep = 0.0, 1.0, 0.1\n",
        "line_thickness = 1.5\n",
        "line_style = \"--\"\n",
        "line_color = \"#383535\"\n",
        "target_col = \"Hausdorff Distance\"\n",
        "# ===========================================================\n",
        "\n",
        "# Load and merge all Excel files\n",
        "all_dfs = []\n",
        "for file in glob.glob(os.path.join(folder_path, \"*.xlsx\")):\n",
        "    model_name = os.path.splitext(os.path.basename(file))[0]\n",
        "\n",
        "    if any(m in model_name for m in [\"3DAttention\",\"MedSam\",\"ResUNet\",\"ReconNet\",\"VNet\"]):\n",
        "        df = pd.read_excel(file)\n",
        "\n",
        "        # --- Normalize column names ---\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        if target_col not in df.columns:\n",
        "            print(f\"⚠️ Skipping {file}, no column '{target_col}' found.\")\n",
        "            continue\n",
        "\n",
        "        # --- Identify category ---\n",
        "        if \"whole\" in model_name.lower():\n",
        "            category = \"whole\"\n",
        "        elif \"crop\" in model_name.lower():\n",
        "            category = \"crop\"\n",
        "        else:\n",
        "            raise ValueError(f\"Category not found in {file}\")\n",
        "\n",
        "        # --- Add metadata ---\n",
        "        df[\"Model\"] = next(m for m in [\"3DAttention\",\"MedSam\",\"ResUNet\",\"ReconNet\",\"VNet\"] if m in model_name)\n",
        "        df[\"Category\"] = category\n",
        "\n",
        "        # --- Ensure numeric column ---\n",
        "        df[target_col] = pd.to_numeric(df[target_col], errors=\"coerce\")\n",
        "\n",
        "        all_dfs.append(df)\n",
        "\n",
        "# Combine data\n",
        "if not all_dfs:\n",
        "    raise ValueError(\"❌ No valid data loaded. Check filenames and column names.\")\n",
        "data = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "print(\"✅ Data loaded:\", data.shape)\n",
        "print(data[[target_col, \"Model\", \"Category\"]].head())\n",
        "\n",
        "# ================= Plotting =================\n",
        "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
        "plt.figure(figsize=figsize)\n",
        "ax = plt.gca()\n",
        "\n",
        "# --- Boxplots ---\n",
        "sns.boxplot(\n",
        "    data=data,\n",
        "    x=\"Model\",\n",
        "    y=target_col,\n",
        "    hue=\"Category\",\n",
        "    palette=colors,\n",
        "    width=0.8,\n",
        "    dodge=True,\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# --- Scatter points ---\n",
        "sns.stripplot(\n",
        "    data=data,\n",
        "    x=\"Model\",\n",
        "    y=target_col,\n",
        "    hue=\"Category\",\n",
        "    dodge=True,\n",
        "    palette=colors,\n",
        "    alpha=0.7,\n",
        "    linewidth=0.5,\n",
        "    edgecolor=\"black\",\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Remove duplicate legends (since both box & strip added)\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(handles[:2], labels[:2], title=\"Category\")\n",
        "\n",
        "# --- Customization ---\n",
        "ax.set_ylim(ymin, ymax)\n",
        "ax.set_yticks(np.arange(ymin, ymax + ystep, ystep))\n",
        "ax.legend_.remove()\n",
        "for spine in ax.spines.values():\n",
        "    spine.set_visible(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"/content/drive/MyDrive/val_Hausdorff.png\", dpi=400, bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "536SnBORLgpn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}